{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(100)\n",
    "\n",
    "def prox_l1(y,alpha):\n",
    "    ## \\arg\\min\\|x\\|_1+\\frac{1}{2\\alpha}\\|x-y\\|_2^2\n",
    "    x = y.copy()\n",
    "    x[y>alpha] = x[y>alpha]-alpha\n",
    "    x[y<-alpha] = x[y<-alpha]+alpha\n",
    "    x[abs(y)-alpha<=0] = 0\n",
    "    return x\n",
    "def project_nonnegtive(x):\n",
    "    x[x<0]=0\n",
    "    return x\n",
    "def prox_l1_nonnegtive(y,alpha):\n",
    "    return project_nonnegtive(prox_l1(y,alpha))\n",
    "prox_l1(-np.array(range(5)),1)\n",
    "\n",
    "\n",
    "N = 100\n",
    "c = 3\n",
    "lambda1 = 1\n",
    "numworker = 5\n",
    "maxiter = 500\n",
    "def generate_component(i):\n",
    "    if i==0:\n",
    "        def _fi(x):\n",
    "            return (x[0]-c)*(x[0]-c)+(x[1]+c)*(x[1]+c)*0.5\n",
    "        def _nabla_fi(x):\n",
    "            _tmp = np.zeros(N)\n",
    "            _tmp[0]=2*x[0]-2*c\n",
    "            _tmp[1]=x[1]+c\n",
    "            return _tmp\n",
    "    elif i==N-1:\n",
    "        def _fi(x):\n",
    "            return (x[i-1]+c)*(x[i-1]+c)*0.5+(x[i]-c)*(x[i]-c)*0.5\n",
    "        def _nabla_fi(x):\n",
    "            _tmp = np.zeros(N)\n",
    "            _tmp[i-1]=x[i-1]+c\n",
    "            _tmp[i]=x[i]-c\n",
    "            return _tmp\n",
    "    else:\n",
    "        def _fi(x):\n",
    "            return 0.5*(x[i-1]+c)*(x[i-1]+c)+(x[i]-c)*(x[i]-c)*0.5+(x[i+1]+c)*(x[i+1]+c)*0.5\n",
    "        def _nabla_fi(x):\n",
    "            _tmp = np.zeros(N)\n",
    "            _tmp[i-1]=x[i-1]+c\n",
    "            _tmp[i]=x[i]-c\n",
    "            _tmp[i+1]=x[i+1]+c\n",
    "            return _tmp\n",
    "    return _fi,_nabla_fi\n",
    "\n",
    "def generate_worker_operator(numworker,nablalist,mode='ordered'):\n",
    "    N = len(nablalist)\n",
    "    capicity = N//numworker\n",
    "    remain = N%numworker\n",
    "    workerlist = [[] for i in range(numworker)]\n",
    "    if mode == 'random':\n",
    "        r=[i for i in range(N)]\n",
    "        np.random.shuffle(r)\n",
    "        queuelist = r\n",
    "    if mode == 'ordered':\n",
    "        queuelist = range(N)\n",
    "    i = 0\n",
    "    for i_worker in range(numworker):\n",
    "        for i_cap in range(capicity + (1 if i_worker<remain else 0)):\n",
    "            workerlist[i_worker].append(nablalist[queuelist[i]])\n",
    "            i+=1\n",
    "    def _operatorlist_combine(operatorlist):\n",
    "        def _operatorlist_combined(x):\n",
    "            res = 0\n",
    "            for operator in operatorlist:\n",
    "                res += operator(x)\n",
    "            return res\n",
    "        return _operatorlist_combined\n",
    "    return list(map(_operatorlist_combine,workerlist))\n",
    "\n",
    "def generate_target_operator(valuelist):\n",
    "    def _target_function(x):\n",
    "        s = 0\n",
    "        for value_function in valuelist:\n",
    "            s+=value_function(x)\n",
    "        s = s+lambda1*np.abs(x).sum()\n",
    "        return s\n",
    "    return _target_function\n",
    "        \n",
    "\n",
    "valuelist,nablalist = zip(*list(map(generate_component,range(N))))\n",
    "\n",
    "### Prepare the workers\n",
    "worker_gradient_operator = generate_worker_operator(numworker,nablalist,mode='ordered')\n",
    "target = generate_target_operator(valuelist)\n",
    "\n",
    "### Begin the loop\n",
    "def piag(eta,alpha=0.01):\n",
    "    ### initialization x\n",
    "    x = np.ones(N)*10\n",
    "    xold = np.ones(N)*10\n",
    "    ### initialization gradient workers\n",
    "    slave_gradient = np.zeros([numworker,N])\n",
    "    master_gradient = np.zeros([numworker,N])\n",
    "    for i in range(numworker):\n",
    "        slave_gradient[i] = worker_gradient_operator[i](x)\n",
    "        master_gradient[i] = worker_gradient_operator[i](x)\n",
    "\n",
    "    resulttable=[]\n",
    "    for it in range(maxiter):\n",
    "        i = np.random.randint(numworker)\n",
    "        ### Update the ith gradient in the master from the ith worker\n",
    "        master_gradient[i] = slave_gradient[i]\n",
    "        ### Recalculate the gradient\n",
    "        gradient = master_gradient.sum(0)\n",
    "        ### Update x\n",
    "        y = x - alpha*gradient+eta*(x-xold)\n",
    "        xold = x.copy()\n",
    "        x = prox_l1_nonnegtive(y,alpha*lambda1)\n",
    "        ### Send x to the ith worker\n",
    "        ### Let the ith worker update the ith gradient\n",
    "        slave_gradient[i] = worker_gradient_operator[i](x)\n",
    "        if it%1==0:\n",
    "            resulttable.append(x)\n",
    "    return resulttable\n",
    "\n",
    "### Begin the loop\n",
    "def piag2(eta,mode=\"acc3\",alpha=0.01,maxiter=500):\n",
    "    ### initialization x\n",
    "    x = np.ones(N)\n",
    "    xold = np.ones(N)\n",
    "    y = np.ones(N)\n",
    "    yold = np.ones(N)\n",
    "    ### initialization gradient workers\n",
    "    slave_gradient = np.zeros([numworker,N])\n",
    "    master_gradient = np.zeros([numworker,N])\n",
    "    for i in range(numworker):\n",
    "        slave_gradient[i] = worker_gradient_operator[i](x)\n",
    "        master_gradient[i] = worker_gradient_operator[i](x)\n",
    "\n",
    "    resulttable=[]\n",
    "    for it in range(maxiter):\n",
    "        i = np.random.randint(numworker)\n",
    "        ### Update the ith gradient in the master from the ith worker\n",
    "        master_gradient[i] = slave_gradient[i]\n",
    "        ### Recalculate the gradient\n",
    "        gradient = master_gradient.sum(0)\n",
    "        ### Update x\n",
    "        if mode == \"acc1\":\n",
    "            #yold = y.copy()\n",
    "            y = x - alpha*gradient        \n",
    "            y = prox_l1_nonnegtive(y,alpha*lambda1)\n",
    "            x = y + eta*(y-x)\n",
    "        if mode == \"acc2\":\n",
    "            xold = x.copy()\n",
    "            x = x - alpha*gradient        \n",
    "            x = prox_l1_nonnegtive(x,alpha*lambda1)\n",
    "            x = x + eta*(x-xold)\n",
    "        if mode == \"acc3\":\n",
    "            yold = y.copy()       \n",
    "            y = prox_l1_nonnegtive(x - alpha*gradient,alpha*lambda1)\n",
    "            x = y+eta*(y-yold)\n",
    "        if mode == \"acc4\":\n",
    "            yold = y.copy()\n",
    "            y = prox_l1_nonnegtive(y - alpha*gradient,alpha*lambda1)\n",
    "            x = y+eta*(y-yold)\n",
    "        if mode == \"acc5\":\n",
    "            yold = y.copy()\n",
    "            y = prox_l1_nonnegtive(x - alpha*gradient+eta*(x-xold),alpha*lambda1)\n",
    "            xold = x.copy()\n",
    "            x = y+eta*(y-yold)\n",
    "        ### Send x to the ith worker\n",
    "        ### Let the ith worker update the ith gradient\n",
    "        slave_gradient[i] = worker_gradient_operator[i](x)\n",
    "        if it%1==0:\n",
    "            resulttable.append(y)\n",
    "    return resulttable\n",
    "\n",
    "def piag3(eta1,eta2,alpha=0.01,maxiter=500):\n",
    "    ### initialization x\n",
    "    x = np.ones(N)\n",
    "    xold = np.ones(N)\n",
    "    y = np.ones(N)\n",
    "    yold = np.ones(N)\n",
    "    z = np.ones(N)\n",
    "    zold = np.ones(N)\n",
    "    ### initialization gradient workers\n",
    "    slave_gradient = np.zeros([numworker,N])\n",
    "    master_gradient = np.zeros([numworker,N])\n",
    "    for i in range(numworker):\n",
    "        slave_gradient[i] = worker_gradient_operator[i](x)\n",
    "        master_gradient[i] = worker_gradient_operator[i](x)\n",
    "\n",
    "    resulttable=[]\n",
    "    for it in range(maxiter):\n",
    "        i = np.random.randint(numworker)\n",
    "        ### Update the ith gradient in the master from the ith worker\n",
    "        master_gradient[i] = slave_gradient[i]\n",
    "        ### Recalculate the gradient\n",
    "        gradient = master_gradient.sum(0)\n",
    "        ### Update x\n",
    "        \n",
    "        y = x + eta1*(x-xold)\n",
    "        zold = z.copy()\n",
    "        z = prox_l1_nonnegtive(y - alpha*gradient,alpha*lambda1)\n",
    "        xold = x.copy()\n",
    "        x = z + 0*(z-zold)\n",
    "\n",
    "        ### Send x to the ith worker\n",
    "        ### Let the ith worker update the ith gradient\n",
    "        slave_gradient[i] = worker_gradient_operator[i](x)\n",
    "        if it%1==0:\n",
    "            resulttable.append(y)\n",
    "    return resulttable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "## for Palatino and other serif fonts use:\n",
    "#rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "rc('text', usetex=True)\n",
    "iters = 5000\n",
    "x_star = np.zeros(N)\n",
    "x_star[0] = max(0,(c-lambda1)/3)\n",
    "F_star = target(x_star).sum(0)\n",
    "print('F_star is:',F_star )\n",
    "\n",
    "markerlist = ['s','.','x','*','o']\n",
    "colorlist = ['royalblue','cornflowerblue','steelblue','skyblue','powderblue']\n",
    "\n",
    "alpha=0.0066\n",
    "etatable=[0.0,0.2,0.4,0.6,0.8]\n",
    "\n",
    "resulttablelistlist = []\n",
    "Loss_list = np.zeros((5,iters))\n",
    "for repeat in range(1):\n",
    "    k = 0\n",
    "    resulttablelist = []\n",
    "    for eta in etatable:\n",
    "        print(eta)\n",
    "        x = piag2(eta,alpha=alpha,maxiter=iters)\n",
    "        for i in  range(iters):\n",
    "            loss_value = target(x[i]).sum(0)\n",
    "            # print('The '+str(i)+'-th Loss is:', loss_value)\n",
    "            Loss_list[k,i] = loss_value\n",
    "        resulttablelist.append(x)\n",
    "        k = k+1 \n",
    "    resulttablelistlist.append(resulttablelist)\n",
    "\n",
    "i=0\n",
    "resulttablelist = (((np.array(resulttablelistlist)-x_star)**2)).sum(3).mean(0)\n",
    "plt.figure(num=1)\n",
    "plt.ylim(1e-30,1e5)\n",
    "for resulttable in resulttablelist:\n",
    "    plt.semilogy(range(iters), resulttable, color = colorlist[i], marker=markerlist[i], markevery=200)\n",
    "    i=i+1\n",
    "\n",
    "pho=1/(2*alpha+1)\n",
    "z0=resulttablelistlist[0][0][0]\n",
    "z1=resulttablelistlist[0][0][1]\n",
    "thbound=(pho*np.linalg.norm(z1-x_star)**2+np.linalg.norm(z0-x_star)**2+0.5*pho*np.linalg.norm(z1-z0)**2)*pho**np.array(range(iters))\n",
    "plt.semilogy(thbound, linestyle='dashed',color=[0,0,0])\n",
    "leg = plt.legend([r'PIAG',r'PIAG with $\\beta=0.2$',r'PIAG with $\\beta=0.4$',r'PIAG with $\\beta=0.6$',r'PIAG with $\\beta=0.8$',r'PIAG:Theoretical bound'],loc='upper right')\n",
    "frame = leg.get_frame()\n",
    "frame.set_alpha(1)  \n",
    "frame.set_facecolor('none') \n",
    "plt.ylabel(r\"$\\|x_k-x^\\ast\\|^2$\",\n",
    "          fontsize=16, color='black')\n",
    "plt.xlabel(r\"Iterate $k$\")\n",
    "\n",
    "plt.savefig(\"fig/toy_x_alpha_\"+str(alpha)+\".eps\")\n",
    "\n",
    "plt.figure(num=2)\n",
    "plt.ylim(1e-15,1e5)\n",
    "for i in range(5):\n",
    "    # iter_k = np.array(range(iters))\n",
    "    # print(iter_k)\n",
    "    plt.semilogy((Loss_list[i,:]-F_star+1e-32).tolist(), color = colorlist[i], marker=markerlist[i], markevery=200)\n",
    "\n",
    "pho=1/(2*alpha+1)\n",
    "# pho = 1/(alpha/8+1)\n",
    "z0=resulttablelistlist[0][0][0]\n",
    "z1=resulttablelistlist[0][0][1]\n",
    "z2=resulttablelistlist[0][0][2]\n",
    "C1=target(z2).sum(0) - F_star + (target(z1).sum(0) - F_star)* pho + 0.25/alpha *pho * np.linalg.norm(z1-z0)**2\n",
    "C1 = target(z1).sum(0) - F_star\n",
    "Loss_thbound=C1*pho**np.array(range(iters))\n",
    "print(Loss_thbound)\n",
    "plt.semilogy(Loss_thbound+1e-32, linestyle='dashed',color=[0,0,0])\n",
    "leg = plt.legend([r'PIAG',r'PIAG with $\\beta=0.2$',r'PIAG with $\\beta=0.4$',r'PIAG with $\\beta=0.6$',r'PIAG with $\\beta=0.8$',r'PIAG:Theoretical bound'],loc='upper right')\n",
    "frame = leg.get_frame()\n",
    "frame.set_alpha(1)  \n",
    "frame.set_facecolor('none') \n",
    "plt.ylabel(r\"$F(x_k)-F^{\\ast}$\",\n",
    "          fontsize=16, color='black')\n",
    "plt.xlabel(r\"Iterate $k$\")\n",
    "plt.savefig(\"fig/toy_loss_alpha_\"+str(alpha)+\".eps\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r(0): 0.0006599571117700265\n",
      "r(0.04): 0.0005230352554731966\n",
      "r(0.08): 4.125373520242919e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def rho(beta, sigma, L, tau):\n",
    " a = 8*(2+beta)/sigma\n",
    " Q = L/sigma\n",
    " b = (1 + (1-83*beta/16)/(24*(2+beta)*Q))**(1/(1+tau))\n",
    " return a * (b-1)\n",
    "\n",
    "print('r(0):', rho(0,2,101,4))\n",
    "print('r(0.04):', rho(0.04,2,101,4))\n",
    "print('r(0.08):', rho(15/83,2,101,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "np.random.seed(104)\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "## for Palatino and other serif fonts use:\n",
    "#rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "rc('text', usetex=True)\n",
    "plt.figure(num=1)\n",
    "x = np.zeros(N)\n",
    "x[0] = max(0,(c-lambda1)/3)\n",
    "x = x.reshape((-1,N))\n",
    "\n",
    "mk = ['o','*','d','s','1','v','p','+','8','h']\n",
    "i = 0\n",
    "etatable = [0.0]\n",
    "# alpha_table= 0.00066 * np.array([2**6,2**6+2**1, 2**6+2**2, 2**6+2**3, 2**6+2**4,  2**6+2**5, 2**7])\n",
    "# alpha_table= 0.00066 * np.array([2**6, 2**7,2**7+1/2**2,2**7+1/2,2**7+1,2**7+2,2**7+2**2,2**7+2**3,2**7+2**4, 2**7+2**5,2**7+2**6, 2**8,2**9])\n",
    "alpha_table = 0.00066 * np.array([2**7])\n",
    "print(alpha_table)\n",
    "mean_iters = 100\n",
    "category_colors1 = plt.get_cmap('Blues')(np.linspace(0.1, 0.7, mean_iters))\n",
    "count_num = np.zeros((len(alpha_table),1))\n",
    "tol = 1e-25\n",
    "for alpha in alpha_table:\n",
    "    for eta in etatable:\n",
    "        err_total = np.zeros((1000,mean_iters))\n",
    "        count = 0\n",
    "        for k in range(mean_iters):\n",
    "            x_rec = np.array(piag3(eta,0,alpha=alpha,maxiter=1000))\n",
    "            err = np.sum((x_rec-x)**2,axis=1)+1e-32\n",
    "            plt.semilogy( err, color=category_colors1[k], alpha=0.3)\n",
    "            if err[-1] < tol:\n",
    "                count = count + 1\n",
    "            err_total[:,k] = err\n",
    "        count_num[i,0] = count\n",
    "        print('alpha:', alpha)\n",
    "        print('beta:', eta)\n",
    "        print('converged num:', count)\n",
    "        if eta == 0:\n",
    "            la = r'PIAG with $\\alpha=0.00066 \\times 2^7$'\n",
    "            # la = r'PIAG'\n",
    "            plt.semilogy(np.mean(err_total,1), color='mediumblue', marker=mk[i], markerfacecolor='none', markeredgecolor='darkblue', markevery=100,  label = la)\n",
    "        else:\n",
    "            la = r'iPIAG with $\\beta=$' + str(eta)\n",
    "            plt.semilogy(np.mean(err_total,1), color=[0,0,1], label = la)\n",
    "        \n",
    "        i = i+1\n",
    "print(count_num)\n",
    "\n",
    "category_colors2 = plt.get_cmap('Oranges')(np.linspace(0.1, 0.5, mean_iters))\n",
    "etatable=[0.3]\n",
    "alpha_table = 0.00066 * np.array([2**4])\n",
    "for alpha in alpha_table:\n",
    "    for eta in etatable:\n",
    "        print('alpha:', alpha)\n",
    "        print('beta:', eta)\n",
    "        err_total = np.zeros((1000,mean_iters))\n",
    "        count = 0\n",
    "        for k in range(mean_iters):\n",
    "            x_rec = np.array(piag3(eta,0,alpha=alpha,maxiter=1000))\n",
    "            err = np.sum((x_rec-x)**2,axis=1)+1e-32\n",
    "            err_total[:,k] = err\n",
    "            if err[-1] < tol:\n",
    "                count = count + 1\n",
    "            plt.semilogy(err, color=category_colors2[k], alpha=0.3)\n",
    "        print('iPIAG converged num:',count)\n",
    "        if eta == 0:\n",
    "            la = r'PIAG with $\\alpha=$'+ str(alpha)\n",
    "            plt.semilogy( np.mean(err_total,1), color=[0,0.1*i,0], alpha= 0.3, label=la)\n",
    "        else:\n",
    "            la = r'iPIAG with $\\alpha = 0.00066 \\times 2^4$, $\\beta = 0.3$'\n",
    "            # la = r'iPIAG with $\\beta=$' + str(eta)\n",
    "            # la = r'iPIAG'\n",
    "            plt.semilogy( np.mean(err_total,1), color='orangered',marker=mk[i], markerfacecolor='none', markeredgecolor='darkred', markevery=100, label=la)\n",
    "        \n",
    "        i = i+1\n",
    "\n",
    "plt.ylabel(r\"$\\|x_k-x^\\ast\\|^2$\",fontsize=16)\n",
    "plt.xlabel(r\"Iterate $k$\")\n",
    "\n",
    "\n",
    "plt.legend(bbox_to_anchor=(0.5, 1.1), loc=10, borderaxespad=0, edgecolor='grey')\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig/alpha_compare_9.png',dpi=600)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f2668d90d229e1ed0fbabd69185b87e8835b49c6b2a044cb1d7ba3c84094aae"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('hehe': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
